{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitidsconda6aac95af6de54c59bceda5e4272aaa84",
   "display_name": "Python 3.7.6 64-bit ('IDS': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nume studenti:\n",
    "- Alexandra Manole\n",
    "- Teodor Mihaescu\n",
    "\n",
    "## Grupa: 382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set 4: Adult\n",
    "### (Missing values: yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 15 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Age            32561 non-null  int64 \n 1   WorkClass      30725 non-null  object\n 2   Fnlwgt         32561 non-null  int64 \n 3   Education      32561 non-null  object\n 4   EducationNum   32561 non-null  int64 \n 5   MaritalStatus  32561 non-null  object\n 6   Occupation     30718 non-null  object\n 7   Relationship   32561 non-null  object\n 8   Race           32561 non-null  object\n 9   Sex            32561 non-null  object\n 10  CapitalGain    32561 non-null  int64 \n 11  CapitalLoss    32561 non-null  int64 \n 12  HoursPerWeek   32561 non-null  int64 \n 13  NativeCountry  31978 non-null  object\n 14  Income         32561 non-null  object\ndtypes: int64(6), object(9)\nmemory usage: 3.7+ MB\n"
    }
   ],
   "source": [
    "data = pd.read_csv('./Datasets/adult.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values imputation\n",
    "\"\"\"\n",
    "Observam ca avem missing values in 3 dintre atribute:\n",
    "- WorkClass\n",
    "- Occupation\n",
    "- NativeCountry\n",
    "\n",
    "Din acest motiv vom folosi un fillna pentru calcularea valorilor ce ar putea substitui missing values. Vom crea o noua clasa unknown pentru fiecare valoare lipsa. Nu alegem alta metoda de fill, precum: cea mai itnalnita valoare, medie, mediana, etc. deoarece umplerea atributelor ce contin missing values cu astfel de metode ar putea influenta drastic datele de iesire. (De exemplu: se observa ca sunt inregistrari cu persoane ce castiga anual peste $50k, la workClass avand missingValue, daca am substitui o astfel de valoare lipsa cu never-worked am ajunge sa denaturam ponderile categoriei persoanelor ce nu au lucrat niciodata, acest lucru ducand la coruperea estimarilor finale)\n",
    "\"\"\"\n",
    "data.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregateste y\n",
    "y = data.loc[:, 'Income']\n",
    "y = np.where(y == '<=50K', 0, 1).reshape(data.shape[0], 1)\n",
    "y = pd.DataFrame(y, columns=['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregateste X (+ One-hot encoding pe datele categoriale din data)\n",
    "X = data['Age']\n",
    "\n",
    "data['WorkClass'] = pd.Categorical(data['WorkClass'])\n",
    "X_categ = pd.get_dummies(data['WorkClass'], prefix='wc')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "X = pd.concat([X, data['Fnlwgt']], axis=1)\n",
    "\n",
    "data['Education'] = pd.Categorical(data['Education'])\n",
    "X_categ = pd.get_dummies(data['Education'], prefix='ed')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "X = pd.concat([X, data['EducationNum']], axis=1)\n",
    "\n",
    "data['MaritalStatus'] = pd.Categorical(data['MaritalStatus'])\n",
    "X_categ = pd.get_dummies(data['MaritalStatus'], prefix='ms')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "data['Occupation'] = pd.Categorical(data['Occupation'])\n",
    "X_categ = pd.get_dummies(data['Occupation'], prefix='oc')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "data['Relationship'] = pd.Categorical(data['Relationship'])\n",
    "X_categ = pd.get_dummies(data['Relationship'], prefix='rl')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "data['Race'] = pd.Categorical(data['Race'])\n",
    "X_categ = pd.get_dummies(data['Race'], prefix='rc')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "data['Sex'] = pd.Categorical(data['Sex'])\n",
    "X_categ = pd.get_dummies(data['Sex'], prefix='sx')\n",
    "X = pd.concat([X, X_categ], axis=1)\n",
    "\n",
    "X = pd.concat([X, data.loc[:, 'CapitalGain':'HoursPerWeek']], axis=1)\n",
    "\n",
    "data['NativeCountry'] = pd.Categorical(data['NativeCountry'])\n",
    "X_categ = pd.get_dummies(data['NativeCountry'], prefix='nc')\n",
    "X = pd.concat([X, X_categ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaleaza datele\n",
    "X_columns = X.columns\n",
    "X_index = X.index\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = pd.DataFrame(min_max_scaler.fit_transform(X), columns=X_columns, index=X_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separarea setului de date\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 16475, 1: 5232})\nCounter({0: 8245, 1: 2609})\n"
    }
   ],
   "source": [
    "# Verifica daca sunt egal distribuite\n",
    "print(Counter(y_train.iloc[:,0]))\n",
    "print(Counter(y_test.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model1 = KNeighborsClassifier(n_neighbors=2)\n",
    "model1.fit(X_train, y_train)\n",
    "y_hat = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[0 0 1 ... 0 0 0]\n\nGround truth:\n[0 0 0 ... 0 0 1]\n\nFailed:\t2098\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat}\\n')\n",
    "print(f'Ground truth:\\n{np.array(y_test.iloc[:, 0])}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != np.array(y_test.iloc[:, 0]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}