{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nume studenti:\n",
    "- Alexandra Manole\n",
    "- Teodor Mihaescu\n",
    "\n",
    "## Grupa: 382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set 2: Energy Efficency\n",
    "### (Missing values: no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 768 entries, 0 to 767\nData columns (total 10 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   X1      768 non-null    float64\n 1   X2      768 non-null    float64\n 2   X3      768 non-null    float64\n 3   X4      768 non-null    float64\n 4   X5      768 non-null    float64\n 5   X6      768 non-null    float64\n 6   X7      768 non-null    float64\n 7   X8      768 non-null    float64\n 8   Y1      768 non-null    float64\n 9   Y2      768 non-null    float64\ndtypes: float64(10)\nmemory usage: 60.1 KB\n"
    }
   ],
   "source": [
    "# Citeste datele\n",
    "data = pd.read_csv('./Datasets/energy.csv').iloc[:768,:-2]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregateste datele\n",
    "X = data.loc[:, :'X8']\n",
    "# y = data.loc[:, 'Y1':]\n",
    "y1 = data.loc[:, 'Y1']\n",
    "y2 = data.loc[:, 'Y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformam problema dintr-una de regresie intr-una de clasificare, dand intervale de clasificare y-ilor\n",
    "\"\"\"\n",
    "Observam ca y1 si y2 se incadreaza intre urmatoarele valori:\n",
    "y1: 6.01-43.1\n",
    "y2: 10.9-48.03\n",
    "\n",
    "Vom imparti datele in urmatoarele clase:\n",
    "y1: 6-10, 10-20, 20-30, 30-40, 40-50\n",
    "y2: 10-20, 20-30, 30-40, 40-50\n",
    "\"\"\"\n",
    "y1 = np.where(np.logical_and(y1>=6, y1<10), 0, y1)\n",
    "y1 = np.where(np.logical_and(y1>=10, y1<20), 1, y1)\n",
    "y1 = np.where(np.logical_and(y1>=20, y1<30), 2, y1)\n",
    "y1 = np.where(np.logical_and(y1>=30, y1<40), 3, y1)\n",
    "y1 = np.where(np.logical_and(y1>=40, y1<50), 4, y1)\n",
    "\n",
    "y2 = np.where(np.logical_and(y2>=10, y2<20), 0, y2)\n",
    "y2 = np.where(np.logical_and(y2>=20, y2<30), 1, y2)\n",
    "y2 = np.where(np.logical_and(y2>=30, y2<40), 2, y2)\n",
    "y2 = np.where(np.logical_and(y2>=40, y2<50), 3, y2)\n",
    "\n",
    "y = np.stack((y1, y2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaleaza datele\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "# y = min_max_scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separarea setului de date\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({1.0: 245, 3.0: 117, 2.0: 111, 4.0: 23, 0.0: 16})\nCounter({1.0: 132, 2.0: 58, 3.0: 50, 4.0: 12, 0.0: 4})\n\n\nCounter({0.0: 230, 2.0: 142, 1.0: 110, 3.0: 30})\nCounter({0.0: 118, 2.0: 74, 1.0: 55, 3.0: 9})\n"
    }
   ],
   "source": [
    "# Verifica daca sunt egal distribuite\n",
    "print(Counter(y_train[:,0]))\n",
    "print(Counter(y_test[:,0]))\n",
    "print(\"\\n\")\n",
    "print(Counter(y_train[:,1]))\n",
    "print(Counter(y_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model1 = MultiOutputClassifier(LogisticRegression(random_state=0, multi_class='multinomial'))\n",
    "model1.fit(X_train, y_train)\n",
    "y_hat = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[1. 0.]\n [1. 1.]\n [1. 0.]\n [4. 3.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[42 57]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scoreers for multiclass output\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, greater_is_better=False, average='micro')\n",
    "accuracy_scorer = metrics.make_scorer(metrics.accuracy_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099945, 0.00099778, 0.        , 0.00099707, 0.00100136]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model1, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099516, 0.        , 0.00099683, 0.00099897, 0.00099897]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model1, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {\n",
    "    'C' : np.linspace(1000, 2000, 10),# C = 1/lambda ; C mare => lambda mic\n",
    "    'solver': ['saga', 'lbfgs']}\n",
    "grid_search = GridSearchCV(estimator = LogisticRegression(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9530165912518853\n{'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "y_hat = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[1. 0.]\n [1. 1.]\n [1. 0.]\n [4. 3.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[44 56]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00299382, 0.00997305, 0.00297642, 0.00299311, 0.00199533]),\n 'score_time': array([0.01896644, 0.01097107, 0.02194047, 0.01894736, 0.01595664]),\n 'test_f1_scorer': array([-0.68181818, -0.78571429, -0.76623377, -0.67320261, -0.74509804]),\n 'train_f1_scorer': array([-0.97882736, -0.96091205, -0.96091205, -0.95121951, -0.96910569]),\n 'test_accuracy': array([0.68181818, 0.78571429, 0.76623377, 0.67320261, 0.74509804]),\n 'train_accuracy': array([0.97882736, 0.96091205, 0.96091205, 0.95121951, 0.96910569])}"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model2, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00199342, 0.00299358, 0.00398993, 0.00199556, 0.0039885 ]),\n 'score_time': array([0.0189507 , 0.01496434, 0.02393794, 0.01695251, 0.02393794]),\n 'test_f1_scorer': array([-0.74675325, -0.67532468, -0.64935065, -0.60784314, -0.7124183 ]),\n 'train_f1_scorer': array([-0.88599349, -0.88436482, -0.89576547, -0.88780488, -0.89593496]),\n 'test_accuracy': array([0.74675325, 0.67532468, 0.64935065, 0.60784314, 0.7124183 ]),\n 'train_accuracy': array([0.88599349, 0.88436482, 0.89576547, 0.88780488, 0.89593496])}"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model2, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {'n_neighbors': list(range(1, 20)), 'p': [1, 2, 3]}\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8674208144796379\n{'n_neighbors': 3, 'p': 1}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model3 = DecisionTreeClassifier(max_depth=2)\n",
    "model3.fit(X_train, y_train)\n",
    "y_hat = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [2. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[1. 0.]\n [1. 1.]\n [1. 0.]\n [4. 3.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[42 64]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099611, 0.00299144, 0.0019908 , 0.00099707, 0.00099778]),\n 'score_time': array([0.00199556, 0.00299215, 0.00199413, 0.00199461, 0.00499249]),\n 'test_f1_scorer': array([-0.79220779, -0.87012987, -0.87662338, -0.74509804, -0.79084967]),\n 'train_f1_scorer': array([-0.82084691, -0.80130293, -0.79967427, -0.83252033, -0.82113821]),\n 'test_accuracy': array([0.79220779, 0.87012987, 0.87662338, 0.74509804, 0.79084967]),\n 'train_accuracy': array([0.82084691, 0.80130293, 0.79967427, 0.83252033, 0.82113821])}"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model3, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099945, 0.00099683, 0.0009973 , 0.00200558, 0.00099778]),\n 'score_time': array([0.00199509, 0.00199628, 0.00199533, 0.00298738, 0.00199461]),\n 'test_f1_scorer': array([-0.66233766, -0.73376623, -0.73376623, -0.66666667, -0.62091503]),\n 'train_f1_scorer': array([-0.79153094, -0.73452769, -0.73452769, -0.74471545, -0.75609756]),\n 'test_accuracy': array([0.66233766, 0.73376623, 0.73376623, 0.66666667, 0.62091503]),\n 'train_accuracy': array([0.79153094, 0.73452769, 0.73452769, 0.74471545, 0.75609756])}"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model3, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {'max_depth': list(range(1,5)),\n",
    "'min_samples_split': np.linspace(1,3,5),\n",
    "'min_samples_leaf': np.linspace(0.1,0.5,5),\n",
    "'max_features': ['sqrt', 'log2', None],\n",
    "'criterion': ['gini', 'entropy']}\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7225490196078432\n{'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 0.2, 'min_samples_split': 1.0}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model4 = RandomForestClassifier(max_depth=2, random_state=0, ccp_alpha=0.2)\n",
    "model4.fit(X_train, y_train)\n",
    "y_hat = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[1. 0.]\n [1. 1.]\n [1. 0.]\n [4. 3.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[79 64]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.24536824, 0.17654991, 0.26528883, 0.19997835, 0.16555929]),\n 'score_time': array([0.01097059, 0.00897455, 0.01447678, 0.00897431, 0.01196647]),\n 'test_f1_scorer': array([-0.62987013, -0.70779221, -0.70779221, -0.7124183 , -0.7124183 ]),\n 'train_f1_scorer': array([-0.71009772, -0.69055375, -0.69055375, -0.68943089, -0.68943089]),\n 'test_accuracy': array([0.62987013, 0.70779221, 0.70779221, 0.7124183 , 0.7124183 ]),\n 'train_accuracy': array([0.71009772, 0.69055375, 0.69055375, 0.68943089, 0.68943089])}"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model4, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.21642137, 0.19749188, 0.1880064 , 0.19547749, 0.15059686]),\n 'score_time': array([0.01296639, 0.01294541, 0.01396251, 0.01097107, 0.01097107]),\n 'test_f1_scorer': array([-0.73376623, -0.73376623, -0.73376623, -0.73856209, -0.73202614]),\n 'train_f1_scorer': array([-0.73452769, -0.73452769, -0.73452769, -0.73333333, -0.73495935]),\n 'test_accuracy': array([0.73376623, 0.73376623, 0.73376623, 0.73856209, 0.73202614]),\n 'train_accuracy': array([0.73452769, 0.73452769, 0.73452769, 0.73333333, 0.73495935])}"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model4, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {'max_depth': list(range(5,10)),\n",
    "'min_samples_split': list(range(1,4)),\n",
    "'min_samples_leaf': list(range(1,5))}\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9373303167420813\n{'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: SVC (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "Folosim metoda SVC pentru a clasifica observatiile. Atunci cand datele sunt in 4 sau mai multe dimensiuni SVC-ul este un hiper-plan. Acesta poate lucra cu valori extreme si din cazua ca permite clasificari eronate poate lucra si cu clasificari suprapuse.\n",
    "\"\"\"\n",
    "model5 = MultiOutputClassifier(SVC(C=2, gamma='auto'))\n",
    "model5.fit(X_train, y_train)\n",
    "y_hat = model5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[1. 0.]\n [1. 0.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[1. 0.]\n [1. 1.]\n [1. 0.]\n [4. 3.]\n [1. 0.]\n [3. 2.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[44 56]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099134, 0.00199103, 0.00199509, 0.        , 0.00099921]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model5, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099802, 0.00099778, 0.00099778, 0.00099778, 0.00099778]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model5, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('IDS': conda)",
   "language": "python",
   "name": "python37664bitidsconda6aac95af6de54c59bceda5e4272aaa84"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}