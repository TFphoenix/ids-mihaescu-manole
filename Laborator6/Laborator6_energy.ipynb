{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nume studenti:\n",
    "- Alexandra Manole\n",
    "- Teodor Mihaescu\n",
    "\n",
    "## Grupa: 382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set 2: Energy Efficency\n",
    "### (Missing values: no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 768 entries, 0 to 767\nData columns (total 10 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   X1      768 non-null    float64\n 1   X2      768 non-null    float64\n 2   X3      768 non-null    float64\n 3   X4      768 non-null    float64\n 4   X5      768 non-null    float64\n 5   X6      768 non-null    float64\n 6   X7      768 non-null    float64\n 7   X8      768 non-null    float64\n 8   Y1      768 non-null    float64\n 9   Y2      768 non-null    float64\ndtypes: float64(10)\nmemory usage: 60.1 KB\n"
    }
   ],
   "source": [
    "# Citeste datele\n",
    "data = pd.read_csv('./Datasets/energy.csv').iloc[:768,:-2]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregateste datele\n",
    "X = data.loc[:, :'X8']\n",
    "# y = data.loc[:, 'Y1':]\n",
    "y1 = data.loc[:, 'Y1']\n",
    "y2 = data.loc[:, 'Y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformam problema dintr-una de regresie intr-una de clasificare, dand intervale de clasificare y-ilor\n",
    "\"\"\"\n",
    "Observam ca y1 si y2 se incadreaza intre urmatoarele valori:\n",
    "y1: 6.01-43.1\n",
    "y2: 10.9-48.03\n",
    "\n",
    "Vom imparti datele in urmatoarele clase:\n",
    "y1: 6-10, 10-20, 20-30, 30-40, 40-50\n",
    "y2: 10-20, 20-30, 30-40, 40-50\n",
    "\"\"\"\n",
    "y1 = np.where(np.logical_and(y1>=6, y1<10), 0, y1)\n",
    "y1 = np.where(np.logical_and(y1>=10, y1<20), 1, y1)\n",
    "y1 = np.where(np.logical_and(y1>=20, y1<30), 2, y1)\n",
    "y1 = np.where(np.logical_and(y1>=30, y1<40), 3, y1)\n",
    "y1 = np.where(np.logical_and(y1>=40, y1<50), 4, y1)\n",
    "\n",
    "y2 = np.where(np.logical_and(y2>=10, y2<20), 0, y2)\n",
    "y2 = np.where(np.logical_and(y2>=20, y2<30), 1, y2)\n",
    "y2 = np.where(np.logical_and(y2>=30, y2<40), 2, y2)\n",
    "y2 = np.where(np.logical_and(y2>=40, y2<50), 3, y2)\n",
    "\n",
    "y = np.stack((y1, y2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaleaza datele\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "# y = min_max_scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separarea setului de date\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({1.0: 247, 3.0: 114, 2.0: 109, 4.0: 28, 0.0: 14})\nCounter({1.0: 130, 2.0: 60, 3.0: 53, 4.0: 7, 0.0: 6})\n\n\nCounter({0.0: 231, 2.0: 149, 1.0: 105, 3.0: 27})\nCounter({0.0: 117, 2.0: 67, 1.0: 60, 3.0: 12})\n"
    }
   ],
   "source": [
    "# Verifica daca sunt egal distribuite\n",
    "print(Counter(y_train[:,0]))\n",
    "print(Counter(y_test[:,0]))\n",
    "print(\"\\n\")\n",
    "print(Counter(y_train[:,1]))\n",
    "print(Counter(y_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model1 = MultiOutputClassifier(LogisticRegression(random_state=0, multi_class='multinomial'))\n",
    "model1.fit(X_train, y_train)\n",
    "y_hat = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [0. 0.]\n [2. 1.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[37 61]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scoreers for multiclass output\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, greater_is_better=False, average='micro')\n",
    "accuracy_scorer = metrics.make_scorer(metrics.accuracy_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099802, 0.00099707, 0.00099683, 0.00200248, 0.        ]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model1, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099874, 0.00097704, 0.        , 0.0009985 , 0.        ]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model1, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {\n",
    "    'C' : np.linspace(1000, 2000, 10),# C = 1/lambda ; C mare => lambda mic\n",
    "    'solver': ['saga', 'lbfgs']}\n",
    "grid_search = GridSearchCV(estimator = LogisticRegression(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8868024132730016\n{'C': 1888.888888888889, 'solver': 'lbfgs'}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi -RandomSearch\n",
    "randomized_search = RandomizedSearchCV(estimator = LogisticRegression(), param_distributions=parameter_grid, random_state=0,  scoring='accuracy', cv=4 )\n",
    "randomized_search.fit(X_train, y1_train)\n",
    "results_rscv = cross_val_score(randomized_search, X_test, y1_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8868024132730016\n{'solver': 'lbfgs', 'C': 1888.888888888889}\n"
    }
   ],
   "source": [
    "print(results_rscv.mean())\n",
    "print(randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "y_hat = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[1. 1.]\n [1. 1.]\n [1. 0.]\n [2. 2.]\n [3. 2.]\n [0. 0.]\n [2. 1.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [0. 0.]\n [2. 1.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[36 54]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00299072, 0.00199771, 0.00099492, 0.00199413, 0.0019486 ]),\n 'score_time': array([0.00997472, 0.00996876, 0.01096797, 0.01196742, 0.00900555]),\n 'test_f1_scorer': array([-0.68181818, -0.78571429, -0.76623377, -0.67320261, -0.74509804]),\n 'train_f1_scorer': array([-0.97882736, -0.96091205, -0.96091205, -0.95121951, -0.96910569]),\n 'test_accuracy': array([0.68181818, 0.78571429, 0.76623377, 0.67320261, 0.74509804]),\n 'train_accuracy': array([0.97882736, 0.96091205, 0.96091205, 0.95121951, 0.96910569])}"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model2, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.0019927 , 0.00199294, 0.00199556, 0.00195217, 0.00203514]),\n 'score_time': array([0.01595879, 0.01092839, 0.009974  , 0.00897598, 0.00793362]),\n 'test_f1_scorer': array([-0.74675325, -0.67532468, -0.64935065, -0.60784314, -0.7124183 ]),\n 'train_f1_scorer': array([-0.88599349, -0.88436482, -0.89576547, -0.88780488, -0.89593496]),\n 'test_accuracy': array([0.74675325, 0.67532468, 0.64935065, 0.60784314, 0.7124183 ]),\n 'train_accuracy': array([0.88599349, 0.88436482, 0.89576547, 0.88780488, 0.89593496])}"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model2, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {'n_neighbors': list(range(1, 20)), 'p': [1, 2, 3]}\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8868024132730016\n{'n_neighbors': 3, 'p': 1}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi -RandomSearch\n",
    "randomized_search = RandomizedSearchCV(estimator = KNeighborsClassifier(), param_distributions=parameter_grid, random_state=0,  scoring='accuracy', cv=4 )\n",
    "randomized_search.fit(X_train, y1_train)\n",
    "results_rscv = cross_val_score(randomized_search, X_test, y1_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8204374057315234\n{'p': 1, 'n_neighbors': 10}\n"
    }
   ],
   "source": [
    "print(results_rscv.mean())\n",
    "print(randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model3 = DecisionTreeClassifier(max_depth=2)\n",
    "model3.fit(X_train, y_train)\n",
    "y_hat = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[2. 2.]\n [1. 0.]\n [1. 0.]\n [2. 2.]\n [2. 2.]\n [0. 0.]\n [2. 2.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [0. 0.]\n [2. 1.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[45 72]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.0019927 , 0.00103092, 0.00099707, 0.0009973 , 0.00299311]),\n 'score_time': array([0.00199676, 0.00196147, 0.00199556, 0.00199533, 0.00099611]),\n 'test_f1_scorer': array([-0.79220779, -0.87012987, -0.87662338, -0.74509804, -0.79084967]),\n 'train_f1_scorer': array([-0.82084691, -0.80130293, -0.79967427, -0.83252033, -0.82113821]),\n 'test_accuracy': array([0.79220779, 0.87012987, 0.87662338, 0.74509804, 0.79084967]),\n 'train_accuracy': array([0.82084691, 0.80130293, 0.79967427, 0.83252033, 0.82113821])}"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model3, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.0009985 , 0.00199485, 0.00099874, 0.00099659, 0.        ]),\n 'score_time': array([0.00299072, 0.00199342, 0.00199485, 0.00199437, 0.00199795]),\n 'test_f1_scorer': array([-0.66233766, -0.73376623, -0.73376623, -0.66666667, -0.62091503]),\n 'train_f1_scorer': array([-0.79153094, -0.73452769, -0.73452769, -0.74471545, -0.75609756]),\n 'test_accuracy': array([0.66233766, 0.73376623, 0.73376623, 0.66666667, 0.62091503]),\n 'train_accuracy': array([0.79153094, 0.73452769, 0.73452769, 0.74471545, 0.75609756])}"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model3, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {'max_depth': list(range(1,5)),\n",
    "'min_samples_split': np.linspace(1,3,5),\n",
    "'min_samples_leaf': np.linspace(0.1,0.5,5),\n",
    "'max_features': ['sqrt', 'log2', None],\n",
    "'criterion': ['gini', 'entropy']}\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6797134238310709\n{'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 0.4, 'min_samples_split': 1.0}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi -RandomSearch\n",
    "randomized_search = RandomizedSearchCV(estimator = DecisionTreeClassifier(), param_distributions=parameter_grid, random_state=0,  scoring='accuracy', cv=4 )\n",
    "randomized_search.fit(X_train, y1_train)\n",
    "results_rscv = cross_val_score(randomized_search, X_test, y1_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7150075414781296\n{'min_samples_split': 1.0, 'min_samples_leaf': 0.2, 'max_features': None, 'max_depth': 3, 'criterion': 'gini'}\n"
    }
   ],
   "source": [
    "print(results_rscv.mean())\n",
    "print(randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model4 = RandomForestClassifier(max_depth=2, random_state=0, ccp_alpha=0.2)\n",
    "model4.fit(X_train, y_train)\n",
    "y_hat = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[3. 2.]\n [1. 0.]\n [1. 0.]\n [3. 2.]\n [3. 2.]\n [1. 0.]\n [3. 2.]\n [3. 2.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [0. 0.]\n [2. 1.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[80 72]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.29989219, 0.25435328, 0.15359092, 0.16552567, 0.15857625]),\n 'score_time': array([0.01196861, 0.01495409, 0.01093507, 0.00899267, 0.00797868]),\n 'test_f1_scorer': array([-0.62987013, -0.70779221, -0.70779221, -0.7124183 , -0.7124183 ]),\n 'train_f1_scorer': array([-0.71009772, -0.69055375, -0.69055375, -0.68943089, -0.68943089]),\n 'test_accuracy': array([0.62987013, 0.70779221, 0.70779221, 0.7124183 , 0.7124183 ]),\n 'train_accuracy': array([0.71009772, 0.69055375, 0.69055375, 0.68943089, 0.68943089])}"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model4, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.20245504, 0.15459132, 0.28426695, 0.20012569, 0.20015192]),\n 'score_time': array([0.01196909, 0.01495695, 0.01694345, 0.00998044, 0.01695538]),\n 'test_f1_scorer': array([-0.73376623, -0.73376623, -0.73376623, -0.73856209, -0.73202614]),\n 'train_f1_scorer': array([-0.73452769, -0.73452769, -0.73452769, -0.73333333, -0.73495935]),\n 'test_accuracy': array([0.73376623, 0.73376623, 0.73376623, 0.73856209, 0.73202614]),\n 'train_accuracy': array([0.73452769, 0.73452769, 0.73452769, 0.73333333, 0.73495935])}"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model4, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch (doar pentru Y1)\n",
    "parameter_grid = {'max_depth': list(range(5,10)),\n",
    "'min_samples_split': list(range(1,4)),\n",
    "'min_samples_leaf': list(range(1,5))}\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9647812971342382\n{'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi -RandomSearch\n",
    "randomized_search = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions=parameter_grid, random_state=0,  scoring='accuracy', cv=4 )\n",
    "randomized_search.fit(X_train, y1_train)\n",
    "results_rscv = cross_val_score(randomized_search, X_test, y1_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9570135746606334\n{'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 7}\n"
    }
   ],
   "source": [
    "print(results_rscv.mean())\n",
    "print(randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: SVC (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\"\"\"\n",
    "Folosim metoda SVC pentru a clasifica observatiile. Atunci cand datele sunt in 4 sau mai multe dimensiuni SVC-ul este un hiper-plan. Acesta poate lucra cu valori extreme si din cazua ca permite clasificari eronate poate lucra si cu clasificari suprapuse.\n",
    "\"\"\"\n",
    "model5 = MultiOutputClassifier(SVC(C=2, gamma='auto'))\n",
    "model5.fit(X_train, y_train)\n",
    "y_hat = model5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicted:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [1. 0.]\n [1. 0.]]\n\nGround truth:\n[[2. 1.]\n [1. 0.]\n [1. 0.]\n [2. 1.]\n [3. 2.]\n [0. 0.]\n [2. 1.]\n [2. 2.]\n [1. 0.]\n [1. 0.]]\n\nFailed:\t[38 61]\n"
    }
   ],
   "source": [
    "print(f'Predicted:\\n{y_hat[:10,:]}\\n')\n",
    "print(f'Ground truth:\\n{y_test[:10,:]}\\n')\n",
    "print(f'Failed:\\t{sum(y_hat != y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = y_train[:, 0].reshape((y_train.shape[0], 1))\n",
    "y2_train = y_train[:, 1].reshape((y_train.shape[0], 1))\n",
    "\n",
    "y1_test = y_test[:, 0].reshape((y_test.shape[0], 1))\n",
    "y2_test = y_test[:, 1].reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.0009985 , 0.00099635, 0.00100064, 0.00099444, 0.00099826]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# Cross Validation Y1\n",
    "results_train = cross_validate(model5, X, y1,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([0.00099754, 0.00099611, 0.00099754, 0.        , 0.00096035]),\n 'score_time': array([0., 0., 0., 0., 0.]),\n 'test_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'train_f1_scorer': array([nan, nan, nan, nan, nan]),\n 'test_accuracy': array([nan, nan, nan, nan, nan]),\n 'train_accuracy': array([nan, nan, nan, nan, nan])}"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# Cross Validation Y2\n",
    "results_train = cross_validate(model5, X, y2,\n",
    "scoring={'f1_scorer': f1_scorer, 'accuracy': accuracy_scorer},\n",
    "return_train_score=True)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi - GridSearch\n",
    "parameter_grid = {'C': np.linspace(0,1,5),\n",
    "'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "'gamma': ['scale', 'auto']}\n",
    "grid_search = GridSearchCV(estimator = SVC(), param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "results_gscv = cross_val_score(grid_search, X_test, y1_test, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8555806938159879\n{'C': 0.75, 'gamma': 'scale', 'kernel': 'poly'}\n"
    }
   ],
   "source": [
    "print(results_gscv.mean())\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cautare hiperparametrii optimi -RandomSearch\n",
    "randomized_search = RandomizedSearchCV(estimator = SVC(), param_distributions=parameter_grid, random_state=0,  scoring='accuracy', cv=4 )\n",
    "randomized_search.fit(X_train, y1_train)\n",
    "results_rscv = cross_val_score(randomized_search, X_test, y1_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8595022624434389\n{'kernel': 'poly', 'gamma': 'scale', 'C': 0.75}\n"
    }
   ],
   "source": [
    "print(results_rscv.mean())\n",
    "print(randomized_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('IDS': conda)",
   "language": "python",
   "name": "python37664bitidsconda6aac95af6de54c59bceda5e4272aaa84"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}